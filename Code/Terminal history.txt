    1  PS1='PEXPE\[\]CT_PROMPT>' PS2='PEXPE\[\]CT_PROMPT_' PROMPT_COMMAND=''
    2  export PAGER=cat
    3  python --version
    4  clear
    5  vi datacleaning.py
    6  py datacleaning.py 
    7  python datacleaning.py 
    8  get clone https://github.com/prasad1825/cloud-ass-1.git
    9  git clone https://github.com/prasad1825/cloud-ass-1.git
   10  ls
   11  cd cloud-ass-1/
   12  ls
   13  pwd
   14  vi QueryResults (1).csv'
   15  vi 'QueryResults (1).csv'
   16  mv 'QueryResults (1).csv'  data1.csv
   17  ls
   18  mv 'QueryResults (2).csv' data2.csv
   19  mv 'QueryResults 3.csv' data3.csv
   20  ls
   21  cd ..
   22  ls
   23  vi datacleaning.py
   24  clear
   25  python datacleaning.py 
   26  vi datacleaning.py
   27  python datacleaning.py 
   28  vi datacleaning.py
   29  python datacleaning.py 
   30  pip install pandas
   31  vi datacleaning.py
   32  python datacleaning.py 
   33  vi datacleaning.py
   34  python datacleaning.py 
   35  vi datacleaning.py
   36  python datacleaning.py 
   37  vi datacleaning.py
   38  python datacleaning.py 
   39  vi datacleaning.py
   40  python datacleaning.py 
   41  vi datacleaning.py
   42  python datacleaning.py 
   43  ls
   44  cd cloud-ass-1/
   45  ls
   46  cp final_data.csv /home/prasad
   47  cd /home/prasad
   48  git commit https://github.com/prasad1825/cloud-ass-1.git
   49  ls
   50  cd ..
   51  ls
   52  cd 
   53  ls
   54  git  clone https://github.com/prasad1825/cloud-ass-1.git
   55  git  clone https://github.com/prasad1825/cloud-ass-1.git clod2
   56  ls
   57  cd clod2/
   58  ls
   59  mv 'QueryResults 4.xls'
   60  mv 'QueryResults 4.xls' data4.csv
   61  ls
   62  cp data4.csv /root/cloud-ass-1/
   63  cd ..
   64  ls
   65  cd cloud-ass-1/
   66  ls
   67  rm -rf final_data.csv 
   68  ls
   69  cd ..
   70  ls
   71  rm -rf clod2
   72  ls
   73  vi datacleaning.py
   74  python datacleaning.py 
   75  ls
   76  cd cloud-ass-1/
   77  ls
   78  cd ..
   79  hadoop
   80  ls /home/hduser
   81  less /etc/passwd
   82  hadoop --version
   83  hive
   84  pig
   85  cle
   86  clear
   87  ls
   88  cat pig_1605275169348.log
   89  clear
   90  cd /usr/local/
   91  ls
   92  cd Hbase
   93  cd ..
   94  cls
   95  ls
   96  cd ..
   97  ls
   98  cd hadoop/
   99  ls
  100  cd ..
  101  hadoop fs
  102  hadoop fs -ls/
  103  hadoop fs -ls /
  104  hadoop fs -ls /hbase
  105  hadoop fs -ls /user
  106  hadoop fs -ls /user/hdfs
  107  ;s
  108  ls
  109  cd /
  110  ls
  111  cd prasad
  112  cd /prasad
  113  pwd
  114  cd /home/prasad
  115  ls
  116  clear
  117  cd ..
  118  ls
  119  cd prasad
  120  ls
  121  locate datacleaning.py
  122  ls
  123  cd /root
  124  ls
  125  pip install snakebit
  126  pip install snakebite
  127  clear
  128  ls
  129  vi loaddata.py
  130  python loaddata.py 
  131  vi loaddata.py
  132  python loaddata.py 
  133  vi loaddata.py
  134  vi loaddata.py
  135  python loaddata.py 
  136  vi loaddata.py
  137  python loaddata.py 
  138  vi loaddata.py
  139  python loaddata.py 
  140  vi loaddata.py
  141  python loaddata.py 
  142  vi loaddata.py
  143  hadoop fs -ls /
  144  vi loaddata.py
  145  python loaddata.py 
  146  vi loaddata.py
  147  python loaddata.py 
  148  python loaddata.py 
  149  vi loaddata.py
  150  python loaddata.py 
  151  vi loaddata.py
  152  python loaddata.py 
  153  vi loaddata.py
  154  python loaddata.py 
  155  ls
  156  vi loaddata.py
  157  ls
  158  python loaddata.py 
  159  localhost
  160  clear
  161  hadoop fs -ls /
  162  hadoop fs cd /hbase
  163  hadoop -conf
  164  hadoop conf
  165  clear
  166  ls /etc/passwd
  167  less /etc/passwd
  168  su - hdfs
  169  su - hbase
  170  hadoop fs -mkdir /data
  171  hadoop fs -ls /
  172  ls
  173  cd cloud-ass-1/
  174  la
  175  ls
  176  hadoop fs -put final_data.csv /data
  177  hadoop fs -ls /data
  178  : mydata = LOAD 'final_data .csv' using PigStorage(',') AS (Index: int, Id:int, PostTypeId:int,
  179  AcceptedAnswerId:int, ParentId:int, CreationDate:datetime, DeletionDate:datetime, Score:int,
  180  ViewCount:int, OwnerUserId:int, OwnerDisplayName:chararray, LastEditorUserId:int,
  181  LastEditorDis playName:chararray, LastEditDate:datetime, LastActivityDate:datetime,
  182  Title:chararray, Tags:chararray, AnswerCount:int, CommentCount:int, FavoriteCount:int,
  183  pig
  184  pig
  185  Pig â€“x mapreduce
  186  pig -x mapreduce
  187  clear
  188  hadoop fs -ls /
  189  hadoop fs -ls /hbase
  190  hadoop fs -ls /user
  191  hadoop fs -ls /user/pig
  192  hadoop fs -copyFromLocal final_data.csv /user/pig
  193  hadoop fs -ls /user/pig
  194  hadoop fs -chmod 777 /data/final_data.csv
  195  hadoop fs -ls /data
  196  pig -x mapreduce
  197  ls
  198  hadoop fs -ls /data
  199  hadoop fs -ls /
  200  cd ..
  201  ls
  202  cd /user
  203  hadoop fs -ls /user
  204  hadoop fs -ls /user/hdfs
  205  hadoop fs -ls /user/pig
  206  cd /root
  207  ls
  208  cd /root/user
  209  cd /user
  210  ls
  211  hadoop fs -ls /
  212  hadoop fs -ls /data
  213  su - hdfs
  214  cd /root
  215  ls
  216  pig -x mapreduce
  217  hadoop fs -ls /data
  218  hadoop fs -get /data/newdata
  219  ls
  220  cd newdata/
  221  ls
  222  hive
  223  ls
  224  hadoop fs -put part-m-00000 /data
  225  hadoop fs -ls /data
  226  hadoop fs -chmod 777 /data/part-m-00000
  227  hadoop fs -ls /data
  228  hadoop fs -cp /data/part-m-00000 /data/data.csv
  229  hadoop fs -ls /data
  230  hive
  231  hadoop fs -ls /data
  232  hadoop fs -ls /
  233  hadoop fs -cp /data/data.csv /
  234  hadoop fs -ls /
  235  hive
  236  ls
  237  cp part-m-00000 data.csv
  238  hive
  239  hive
  240  history
  241  history >> hist.txt
